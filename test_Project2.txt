PRISM
=====

Version: 4.4.beta
Date: Fri Dec 01 14:03:36 EST 2017
Hostname: klyu
Memory limits: cudd=1g, java(heap)=910.5m
Command line: prism Project_Code2.pm -pctl 'multi(R{"totalRewards"}max=? [C], R{"failures"}min=? [C])' -exportadv policy.txt -s -exportstates states.txt -s

Parsing model file "Project_Code2.pm"...

1 property:
(1) multi(R{"totalRewards"}max=? [ C ], R{"failures"}min=? [ C ])

Type:        MDP
Modules:     UAV site_one site_two site_three site_four 
Variables:   uav uav_battery s1 s2 s3 s4 

Building model...

Computing reachable states...

Reachability (BFS): 11 iterations in 0.00 seconds (average 0.000000, setup 0.00)

Time for model construction: 0.021 seconds.

Warning: Deadlocks detected and fixed in 152 states

Type:        MDP
States:      753 (1 initial)
Transitions: 5916
Choices:     3220

Transition matrix: 665 nodes (4 terminal), 5916 minterms, vars: 12r/12c/8nd

Exporting list of reachable states in plain text format to file "states.txt"...

---------------------------------------------------------------------

Model checking: multi(R{"totalRewards"}max=? [ C ], R{"failures"}min=? [ C ])

Warning: Disabling Prob1 since this is needed for adversary generation
Total time for product construction: 0.0 seconds.

States:      753 (1 initial)
Transitions: 5916
Choices:     3220

Transition matrix: 665 nodes (4 terminal), 5916 minterms, vars: 12r/12c/8nd

Prob0A: 1 iterations in 0.00 seconds (average 0.000000, setup 0.00)

yes = 0, no = 0, maybe = 753

Computing remaining probabilities...
Engine: Sparse
Optimising weighted sum for reward objective 1/2: weights (1.0, 0.0)
Iterative method: 12 iterations in 0.00 seconds (average 0.000000, setup 0.00)
Optimal value for weights [1.000000,0.000000] from initial state: 200.000000
Computed point: (200.0, 0.0)
Optimising weighted sum for reward objective 2/2: weights (0.0, 1.0)
Iterative method: 11 iterations in 0.00 seconds (average 0.000000, setup 0.00)
Optimal value for weights [0.000000,1.000000] from initial state: 0.000000
Computed point: (200.0, 0.0)
Optimising weighted sum of objectives: weights (1.0, 0.0)
Iterative method: 12 iterations in 0.00 seconds (average 0.000000, setup 0.00)
Optimal value for weights [1.000000,0.000000] from initial state: 200.000000

Adversary written to file "policy1.txt".
The value iteration(s) took 0.048 seconds altogether.
Number of weight vectors used: 3
Multi-objective value iterations took 0.048 s.

Value in the initial state: [(200.0, -0.0)]

Time for model checking: 0.165 seconds.

Result: [(200.0, -0.0)] (value in the initial state)

Warning: CUDD reports 1 non-zero references.

---------------------------------------------------------------------

Note: There were 2 warnings during computation.

